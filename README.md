# ğŸš€ **Naukri Scraping Tool**  
*A powerful web scraping and analysis tool for job listings on Naukri.com*  

---

## **ğŸ“Œ Project Overview**  
This project is designed to scrape job postings from **Naukri.com** based on user-defined roles and locations. The scraped data is processed, analyzed, and presented through a **Streamlit web application**. Users can explore job listings, extract key insights, and filter relevant roles efficiently.  

---

## **ğŸ›  Features**  
âœ… **Web Scraping with Selenium & BeautifulSoup** â†’ Extract job details like title, company, location, experience, salary, skills, and description.  
âœ… **Data Preprocessing & Cleaning** â†’ Remove duplicates, extract structured data, and process missing values.  
âœ… **Exploratory Data Analysis (EDA)** â†’ Analyze salary trends, required skills, and experience levels using visualizations.  
âœ… **Streamlit Web App** â†’ Interactive UI to search and display job listings dynamically.  
âœ… **Well-Structured Codebase** â†’ Organized into separate modules for scraping, processing, and visualization.  

---

## **ğŸ“‚ Project Structure**  
```
ğŸ“‚ Naukri_Scraping_Tool
 â”£ ğŸ“‚ data                   # Store all scraped CSV/Excel files
 â”ƒ  â”£ ğŸ“„ scraped_jobs_YYYY-MM-DD.xlsx  # Raw scraped data
 â”ƒ  â”£ ğŸ“„ cleaned_jobs_YYYY-MM-DD.csv   # Processed data
 â”£ ğŸ“‚ notebooks              # Jupyter Notebooks for different tasks
 â”ƒ  â”£ ğŸ“„ web_scraper.ipynb   # Web scraping script
 â”ƒ  â”£ ğŸ“„ Machine_Learning_Preprocessing.ipynb   # Data preprocessing script
 â”£ ğŸ“‚ streamlit_app          # Streamlit Web App
 â”ƒ  â”£ ğŸ“„ app.py              # Streamlit UI Code
 â”£ ğŸ“„ requirements.txt       # Project dependencies
 â”£ ğŸ“„ README.md              # Project Documentation
 
```

---

## **ğŸ”§ Installation & Setup**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/Shravani-1325/Naukri_Scraping_Tool.git
cd Naukri-Scraping-Tool
```

### **2ï¸âƒ£ Install Dependencies**  
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Run the Scraper**  
To scrape job listings, update `web_scraper.ipynb` with your desired **job role** and **location**, then execute the script.  

---

## **ğŸ“Š Running the Streamlit App**  
Once the data is scraped and preprocessed, launch the **Streamlit web app** to visualize results.  
Run the following command:  
```bash
streamlit run streamlit_app/app.py
```
Then, open **http://localhost:8501/** in your browser to explore job listings interactively.  

---

## **ğŸ¯ Real-World Impact**  
This tool helps job seekers, recruiters, and analysts by:  
âœ”ï¸ **Identifying job trends & demand** for specific roles.  
âœ”ï¸ **Filtering jobs based on experience, skills, and location.**  
âœ”ï¸ **Saving time** by automating job search processes.  

---

## **ğŸ“Œ Future Enhancements**  
ğŸ”¹ Expand scraping to multiple job platforms.  
ğŸ”¹ Add AI-based salary prediction.  
ğŸ”¹ Improve UI with filters and charts.  

---

